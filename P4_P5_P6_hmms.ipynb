{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pgmpy"
      ],
      "metadata": {
        "id": "XpEFtEuK3LXQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O robot_maze.gif https://www.dropbox.com/scl/fi/x1v960ujfafo5zyzlvkkj/robot_maze.gif?rlkey=3m72wqh4l3aaiyxurku4ow3cn&dl=0\n",
        "!wget -O robot.data https://www.dropbox.com/scl/fi/6kd0vzc4arjm44s3zqtiq/robot.data?rlkey=d1fz4s9awplhqww4zf9h0cm0r&dl=0\n",
        "!wget -O typos10.data https://www.dropbox.com/scl/fi/q84kajej3oa4j0uox32ib/typos10.data?rlkey=gnwazjwqebov0tz6064a861vd&dl=0\n",
        "!wget -O typos20.data https://www.dropbox.com/scl/fi/lktze933nkhqhjo2dhsyf/typos20.data?rlkey=4bfhtgi3a8fy16rnrbxs9kjio&dl=0"
      ],
      "metadata": {
        "id": "s2kjDP07e24H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb0eaf3-a19f-4a3a-c648-d04c3a1b2c7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-17 10:12:57--  https://www.dropbox.com/scl/fi/x1v960ujfafo5zyzlvkkj/robot_maze.gif?rlkey=3m72wqh4l3aaiyxurku4ow3cn\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com/cd/0/inline/CkRiELxSPwMAMb1e7OCWIqWf-o8nvq-yvCqUdzOoAiBWpSlR9BLy-uXfBPAQ2PoI0g_eDBXd08Vj7LNgK2XFBm-HFkbwM3oq3DESal3BJWWdQue_egtQiORJpvJChpZZkW0/file# [following]\n",
            "--2025-02-17 10:12:57--  https://uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com/cd/0/inline/CkRiELxSPwMAMb1e7OCWIqWf-o8nvq-yvCqUdzOoAiBWpSlR9BLy-uXfBPAQ2PoI0g_eDBXd08Vj7LNgK2XFBm-HFkbwM3oq3DESal3BJWWdQue_egtQiORJpvJChpZZkW0/file\n",
            "Resolving uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com (uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com (uca1aab040e27718b74c39f7c83c.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3976 (3.9K) [image/gif]\n",
            "Saving to: ‘robot_maze.gif’\n",
            "\n",
            "robot_maze.gif      100%[===================>]   3.88K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-17 10:12:58 (996 MB/s) - ‘robot_maze.gif’ saved [3976/3976]\n",
            "\n",
            "--2025-02-17 10:12:58--  https://www.dropbox.com/scl/fi/6kd0vzc4arjm44s3zqtiq/robot.data?rlkey=d1fz4s9awplhqww4zf9h0cm0r\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com/cd/0/inline/CkQoGdBfqToA5W0qOdJm3gjmsbo3d3qOOU28dstcPAosoFqg8jub5GlElJT2HIviAIcnONrBP8c-0k4GmFQ5jdW2SVnTCkGcqH0ugw6UMoZ8qW81SjDCHWMOaVvHrKsqaJs/file# [following]\n",
            "--2025-02-17 10:12:58--  https://uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com/cd/0/inline/CkQoGdBfqToA5W0qOdJm3gjmsbo3d3qOOU28dstcPAosoFqg8jub5GlElJT2HIviAIcnONrBP8c-0k4GmFQ5jdW2SVnTCkGcqH0ugw6UMoZ8qW81SjDCHWMOaVvHrKsqaJs/file\n",
            "Resolving uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com (uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com (uc7c5c5ecad0c8b794ec02a53a2e.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 480801 (470K) [text/plain]\n",
            "Saving to: ‘robot.data’\n",
            "\n",
            "robot.data          100%[===================>] 469.53K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-17 10:12:59 (4.70 MB/s) - ‘robot.data’ saved [480801/480801]\n",
            "\n",
            "--2025-02-17 10:13:00--  https://www.dropbox.com/scl/fi/q84kajej3oa4j0uox32ib/typos10.data?rlkey=gnwazjwqebov0tz6064a861vd\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com/cd/0/inline/CkSwacw4r4rqnpVzYvi2OIbAiDrEs_fUawsLmz1dmHJ27fi9fuLoDjzq6xmGGIPHfbAhIK3aiNvYtuE-8S5qYclfDk6-3Hk5gLzJ_hsRJmi07FRXAvS-Ba_j3OD01Aq7F2s/file# [following]\n",
            "--2025-02-17 10:13:01--  https://uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com/cd/0/inline/CkSwacw4r4rqnpVzYvi2OIbAiDrEs_fUawsLmz1dmHJ27fi9fuLoDjzq6xmGGIPHfbAhIK3aiNvYtuE-8S5qYclfDk6-3Hk5gLzJ_hsRJmi07FRXAvS-Ba_j3OD01Aq7F2s/file\n",
            "Resolving uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com (uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com (uc3da5f3a8e80d406bfa470424f4.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 724179 (707K) [text/plain]\n",
            "Saving to: ‘typos10.data’\n",
            "\n",
            "typos10.data        100%[===================>] 707.21K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-17 10:13:01 (6.91 MB/s) - ‘typos10.data’ saved [724179/724179]\n",
            "\n",
            "--2025-02-17 10:13:02--  https://www.dropbox.com/scl/fi/lktze933nkhqhjo2dhsyf/typos20.data?rlkey=4bfhtgi3a8fy16rnrbxs9kjio\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com/cd/0/inline/CkSfpCgAMSgOC0iwK5bZA80h5oXcwWC1Nx9p0WIaUAgKgcvYsnLoVmfrvJG9YrJL53IfBjJoOGYBgnV-srO8RB3C8ZzH6yyovilT_FN2TNaeZGghseR5sGvRnP0sibNcJUM/file# [following]\n",
            "--2025-02-17 10:13:02--  https://uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com/cd/0/inline/CkSfpCgAMSgOC0iwK5bZA80h5oXcwWC1Nx9p0WIaUAgKgcvYsnLoVmfrvJG9YrJL53IfBjJoOGYBgnV-srO8RB3C8ZzH6yyovilT_FN2TNaeZGghseR5sGvRnP0sibNcJUM/file\n",
            "Resolving uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com (uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com (uc37859d3a7eefd6e037839b2a3d.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 724179 (707K) [text/plain]\n",
            "Saving to: ‘typos20.data’\n",
            "\n",
            "typos20.data        100%[===================>] 707.21K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-17 10:13:03 (5.53 MB/s) - ‘typos20.data’ saved [724179/724179]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWEPYhPy3Jxh"
      },
      "source": [
        "# Inference in Hidden Markov Models\n",
        "\n",
        "\n",
        "In this lab session you will work with hidden Markov models (HMMs) using the [pgmpy library](http://www.pgmpy.org). By the end of the session you will be able to\n",
        "\n",
        "- Understand how to learn **hidden Markov models** from data\n",
        "- Implement the **belief propagation** to answer **filtering and prediction** queries\n",
        "- **Implement the Viterbi algorithm** for finding the most likely sequence of hidden states, given some evidence\n",
        "- Experiment with two tasks: a robot navigating on a grid, and how to improve a mispelled text\n",
        "\n",
        "This practice is inspired by https://www.cs.princeton.edu/courses/archive/fall12/cos402/assignments/programs/viterbi/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSujyY-3Jxm"
      },
      "source": [
        "## The Hidden Markov Model\n",
        "\n",
        "A HMM is defined by a Markov chain over hidden variables $h_{1:T}=h_1,h_2,...,h_T$ and it is defined by\n",
        "- a probability distribution over the initial hidden state $p(h_1)$.\n",
        "- a state transition distribution $p(h_t|h_{t-1})$.\n",
        "\n",
        "Each hidden variable $h_t$ influences a corresponding visible variable $v_t$ through the observation model $p(v_t|h_t)$. The joint distribution can be written as\n",
        "$$p(v_{1:T},h_{1:T}) = p(h_1)p(v_1|h_1)\\prod_{t=2}^T p(h_{t}|h_{t-1})p(v_t|h_t).$$\n",
        "\n",
        "Let's define a class that encodes an HMM. This class will create the HMM with a predefined length ``n_vars``:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VfJ988Gu3Jxn"
      },
      "outputs": [],
      "source": [
        "from pgmpy.models import FactorGraph\n",
        "\n",
        "class HMM:\n",
        "    def __init__(self, n_vars, prior_fn, transition_fn, observation_fn, h_states, v_states, h_name='h', v_name='v'):\n",
        "        self.h = [f\"{h_name}{i}\" for i in range(n_vars)]\n",
        "        self.v = [f\"{v_name}{i}\" for i in range(n_vars)]\n",
        "        self.variables = self.h + self.v\n",
        "        self.state_names = dict([(h, h_states) for h in self.h] +\n",
        "                                [(v, v_states) for v in self.v])\n",
        "        self.f = self.create_factors(n_vars, prior_fn, transition_fn, observation_fn)\n",
        "\n",
        "    def create_factors(self, n_vars, prior_fn, transition_fn, observation_fn):\n",
        "        \"\"\"\n",
        "        Given the amount of variables (n_vars) in the hidden markov model, it creates factors for\n",
        "        the prior of h_0, for all the transitions from h_{t-1} to h_t (for t in n_vars), and for\n",
        "        the observation function from h_t to v_t.\n",
        "        Returns a dict where keys are (tuples of) variables and values are factors.\n",
        "        E.g. {\"h_0\": DiscreteFactor,\n",
        "              (\"h_1\", \"h_2\"): DiscreteFactor,\n",
        "              (\"h_1\", \"v_1\"): DiscreteFactor,\n",
        "                           ...\n",
        "              }\n",
        "        \"\"\"\n",
        "\n",
        "        factors = dict()\n",
        "        for i in range(n_vars):\n",
        "            if i == 0:\n",
        "                # Prior factor\n",
        "                factors[self.h[i]] = prior_fn(self.h[i])\n",
        "            else:\n",
        "                # Transition factor\n",
        "                factors[(self.h[i-1], self.h[i])] = transition_fn(self.h[i-1], self.h[i])\n",
        "            # Observation factor\n",
        "            factors[(self.h[i], self.v[i])] = observation_fn(self.h[i], self.v[i])\n",
        "        return factors\n",
        "\n",
        "    def to_factor_graph(self):\n",
        "        G = FactorGraph()\n",
        "        assert set(self.variables) == set(v for f in self.f.values() for v in f.variables)\n",
        "        G.add_nodes_from(self.variables)\n",
        "        G.add_factors(*self.f.values())\n",
        "        G.add_edges_from([(v, f) for f in self.f.values() for v in f.variables])\n",
        "        assert G.check_model()\n",
        "        return G"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLy8NpJ83Jxq"
      },
      "source": [
        "## Basic setting\n",
        "\n",
        "Before tackling larger problems, and to be able to test our implementations, we will first consider a small version of our previous hidden Markov model of weather change over three days, where we can observe if an umbrella has been used or not. We define this factor graph next:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mO6IuzSc3Jxr"
      },
      "outputs": [],
      "source": [
        "from pgmpy.factors.discrete import DiscreteFactor\n",
        "from pgmpy.models import FactorGraph\n",
        "\n",
        "weather_states = [\"sunny\", \"cloudy\", \"rainy\"]\n",
        "umbrella_states = [True, False]\n",
        "\n",
        "def day_prior(d):\n",
        "    return DiscreteFactor(variables=[d],\n",
        "                          cardinality=[3],\n",
        "                          values=[0.3, 0.4, 0.3],\n",
        "                          state_names={d: weather_states})\n",
        "\n",
        "def day_transition(d1, d2): # P(d2|d1)\n",
        "     return DiscreteFactor(variables=[d1, d2],\n",
        "                           cardinality=[3, 3],\n",
        "                           values=[0.7, 0.25, 0.05,\n",
        "                                   0.25, 0.35, 0.4,\n",
        "                                   0.25, 0.5, 0.25],\n",
        "                           state_names={d1: weather_states,\n",
        "                                        d2: weather_states})\n",
        "\n",
        "def take_umbrella_transition(d, u): # P(u|d)\n",
        "    return DiscreteFactor(variables=[d, u],\n",
        "                          cardinality=[3, 2],\n",
        "                          values=[0.2, 0.8,\n",
        "                                  0.6, 0.4,\n",
        "                                  0.95, 0.05],\n",
        "                          state_names={d: weather_states,\n",
        "                                       u: umbrella_states})\n",
        "\n",
        "# Expand the model for 3 days\n",
        "hmm_weather_3 = HMM(n_vars=3,\n",
        "                    prior_fn=day_prior,\n",
        "                    transition_fn=day_transition,\n",
        "                    observation_fn=take_umbrella_transition,\n",
        "                    h_states=weather_states,\n",
        "                    v_states=umbrella_states,\n",
        "                    h_name=\"w\",\n",
        "                    v_name=\"u\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQxgRQD-3Jxr"
      },
      "source": [
        "## Inference Queries\n",
        "\n",
        "We will implement three types of queries:\n",
        "\n",
        "1. **Filtering** : the probability of the current hidden sate given a partial sequence of observations $p(h_t|v_{1:t}=V_{1:t})$.\n",
        "2. **Prediction** : the probability of a future hidden sate given a partial sequence of observations $p(h_s|v_{1:t}=V_{1:t})$, for a $s>t$.\n",
        "3. **Evidence** : the probability of a given a full sequence of observations $p(v_{1:T}=V_{1:T})$.\n",
        "4. **MAP state** : the most likely hidden trajectory given a full sequence of observations $h^*_{1:T} = \\text{arg}\\max p(h_{1:T}|v_{1:T}=V_{1:T})$.\n",
        "\n",
        "A naive way of computing the MAP of the hidden variables can be:\n",
        "1. Clamp the corresponding visible variables $v_{1:t}$ to values $V_{1:t}$.\n",
        "2. Run BP.\n",
        "3. Compute the marginal probability of the subset of hidden variables.\n",
        "3. Get the assignment with maximum probability.\n",
        "\n",
        "\n",
        "The following code calculates the joint hidden trajectory for the weather example with $T=3$ using belief propagation. Clearly, this approach will not scale to larger models. However, we will use it to check that our code is correct.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.inference import BeliefPropagation\n",
        "import numpy as np\n",
        "\n",
        "bp = BeliefPropagation(hmm_weather_3.to_factor_graph())\n",
        "\n",
        "# Compute the joint probability\n",
        "joint = bp.query(variables=['w0','w1','w2'],\n",
        "                 evidence={\"u0\":True,\"u1\":True, \"u2\":True})\n",
        "\n",
        "# Get the index of the maximum value\n",
        "amax = np.argmax(joint.values)\n",
        "print(\"Maximum probability:\", joint.values.flatten()[amax])\n",
        "print(\"State assignment:\", sorted(joint.assignment([amax])[0])) # pgmpy's assignment function gives us the states for the given index"
      ],
      "metadata": {
        "id": "_Vqy630RcKyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8ak2V8a3Jxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69846935-3de9-49d0-af0c-b8dacfa2681a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['w0', 'u2', 'w2', 'u1', 'u0', 'w1']\n",
            "Working graph True\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "import operator\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "\n",
        "def prod(iterable):\n",
        "    \"\"\"Helper function to obtain the product of all the items in the iterable\n",
        "    given as input\"\"\"\n",
        "    return reduce(operator.mul, iterable, 1)\n",
        "\n",
        "class MyBeliefPropagation:\n",
        "    def __init__(self, factor_graph):\n",
        "        assert factor_graph.check_model()\n",
        "        self.original_graph = factor_graph\n",
        "        self.variables = factor_graph.get_variable_nodes()\n",
        "\n",
        "        self.state_names = dict()\n",
        "        for f in self.original_graph.factors:\n",
        "            self.state_names.update(f.state_names)\n",
        "\n",
        "\n",
        "    def get_evidence_factors(self, evidence):\n",
        "        \"\"\"\n",
        "        For each evidence variable v, create a factor with p(v=e)=1. Receives a dict of\n",
        "        evidences, where keys are variables and values are variable states. Returns a list of\n",
        "        DiscreteFactor.\n",
        "        \"\"\"\n",
        "        # For each factor that involves variable v, add another factor with p(v=value)=1.\n",
        "        # Returns a list of evidence factors.\n",
        "        evidence_factors = []\n",
        "\n",
        "        for variable, value in evidence.items():\n",
        "            i = self.state_names[variable].index(value)\n",
        "            values = [0]*len(self.state_names[variable])\n",
        "            values[i] = 1.0\n",
        "            ef = DiscreteFactor(variables=[variable],\n",
        "                                cardinality=[len(values)],\n",
        "                                values=values,\n",
        "                                state_names=self.state_names)\n",
        "            evidence_factors.append(ef)\n",
        "        return evidence_factors\n",
        "\n",
        "    def set_evidence(self, evidence):\n",
        "        \"\"\"\n",
        "        Generates a new graph with the evidence factors\n",
        "        evidence (keys: variables, values: states)\n",
        "        \"\"\"\n",
        "        evidence_factors = self.get_evidence_factors(evidence)\n",
        "        self.working_graph = self.original_graph.copy()\n",
        "        for f in evidence_factors:\n",
        "            self.working_graph.add_factors(f)\n",
        "            for v in f.variables:\n",
        "                self.working_graph.add_edge(v,f)\n",
        "        self.bp_done = False\n",
        "\n",
        "    def factor_ones(self, v):\n",
        "        \"\"\"\n",
        "        Returns a DiscreteFactor for variable v with all ones.\n",
        "        \"\"\"\n",
        "        card = len(self.state_names[v])\n",
        "        return DiscreteFactor(variables=[v],\n",
        "                              cardinality=[card],\n",
        "                              values=[1]*card,\n",
        "                              state_names=self.state_names)\n",
        "\n",
        "    def initialize_messages(self):\n",
        "        \"\"\"\n",
        "        This function creates, for each edge factor-variable, two messages: m(f->v) and\n",
        "        m(v->f). It initiliazies each message as a DiscreteFactor with all ones. It stores all\n",
        "        the messages in a dict of dict. Keys of both dicts are either factors or variables.\n",
        "        Messages are indexed as messages[to][from]. For example, m(x->y) is in messages[y][x].\n",
        "        It's done this way because it will be useful to get all messages that go to a variable\n",
        "        or a factor.\n",
        "        \"\"\"\n",
        "        self.messages = defaultdict(dict)\n",
        "        for f in self.working_graph.get_factors():\n",
        "            for v in f.variables:\n",
        "                self.messages[v][f] = self.factor_ones(v)\n",
        "                self.messages[f][v] = self.factor_ones(v)\n",
        "\n",
        "    def factor_to_variable(self, f, v):\n",
        "        \"\"\"\n",
        "        Computes message m from factor to variable.\n",
        "        It computes it from all messages from all\n",
        "        other variables to the factor (i.e. all variables connected the factor except v).\n",
        "        Returns message m.\n",
        "        \"\"\"\n",
        "        assert v in self.variables and f in self.working_graph.factors\n",
        "        messages_to_f = list(self.messages[f].values())\n",
        "        messages_to_f.remove(self.messages[f][v]) # all except the one from variable v\n",
        "\n",
        "        m = f * prod(messages_to_f)\n",
        "        other_vars = set(m.variables) - set([v])\n",
        "        m.marginalize(other_vars)\n",
        "        return m\n",
        "\n",
        "    def variable_to_factor(self, v, f):\n",
        "        \"\"\"\n",
        "        Computes message m from variable to factor.\n",
        "        It computes it from all messages from all\n",
        "        other factors to the variable (i.e. all factors connected the variable except f).\n",
        "        Returns message m.\n",
        "        \"\"\"\n",
        "        assert v in self.variables and f in self.working_graph.factors\n",
        "        messages_to_v = list(self.messages[v].values())\n",
        "        messages_to_v.remove(self.messages[v][f]) # all except the one from factor f\n",
        "        if len(messages_to_v) == 0: # No neighbors, return 1 (or return None and do not update)\n",
        "            return self.factor_ones(v)\n",
        "        m = prod(messages_to_v)\n",
        "        return m\n",
        "\n",
        "    def update(self, m_to, m_from):\n",
        "        \"\"\"\n",
        "        Performs an update of a message depending on whether it is variable-to-factor or\n",
        "        factor-to-variable.\n",
        "        \"\"\"\n",
        "        if m_from in self.variables:\n",
        "            assert m_to in self.working_graph.factors, f\"m_from: {m_from}\\nm_to: {m_to}\"\n",
        "            self.messages[m_to][m_from] = self.variable_to_factor(m_from, m_to)\n",
        "        else:\n",
        "            assert m_from in self.working_graph.factors and m_to in self.variables, f\"m_from: {m_from}\\nm_to: {m_to}\"\n",
        "            self.messages[m_to][m_from] = self.factor_to_variable(m_from, m_to)\n",
        "\n",
        "    def collect_evidence(self, node, parent=None):\n",
        "        \"\"\"\n",
        "        Passes messages from the leaves to the root of the tree.\n",
        "        The parent argument is used to avoid an infinite recursion.\n",
        "        \"\"\"\n",
        "        for child in self.working_graph.neighbors(node):\n",
        "            if child is not parent:\n",
        "                self.update(node, self.collect_evidence(child, parent=node))\n",
        "        return node\n",
        "\n",
        "    def distribute_evidence(self, node, parent=None):\n",
        "        \"\"\"\n",
        "        Passes messages from the root to the leaves of the tree.\n",
        "        The parent argument is used to avoid an infinite recursion.\n",
        "        \"\"\"\n",
        "        for child in self.working_graph.neighbors(node):\n",
        "            if child is not parent:\n",
        "                self.update(child, node)\n",
        "                self.distribute_evidence(child, parent=node)\n",
        "\n",
        "    def run_bp(self, root):\n",
        "        \"\"\"\n",
        "        After initializing the messages, this function performs Belief Propagation\n",
        "        using collect_evidence and distribute_evidence from the given root node.\n",
        "        \"\"\"\n",
        "        assert root in self.variables, \"Variable not in the model\"\n",
        "        self.initialize_messages()\n",
        "        print('Working graph', self.working_graph.check_model())\n",
        "        self.collect_evidence(root)\n",
        "        self.distribute_evidence(root)\n",
        "        self.bp_done = True\n",
        "\n",
        "    def get_marginal(self, variable):\n",
        "        \"\"\"\n",
        "        To be used after run_bp. Returns p(variable | evidence) unnormalized.\n",
        "        \"\"\"\n",
        "        assert self.bp_done, \"First run BP!\"\n",
        "        return prod(self.messages[variable].values())\n",
        "\n",
        "    def get_marginal_subset(self, variables):\n",
        "        \"\"\"\n",
        "        Returns p(variables | evidence) unnormalized.\n",
        "        \"\"\"\n",
        "        assert self.bp_done, \"First run BP!\"\n",
        "        # IMPLEMENT\n",
        "        product = 1\n",
        "        factor = None\n",
        "        for f in self.working_graph.factors:\n",
        "            #print(f.variables, variables)\n",
        "            if set(variables).issubset(f.variables):\n",
        "                factor = f\n",
        "                break\n",
        "\n",
        "        if factor is None:\n",
        "            raise ValueError('Not valid set of variables')\n",
        "\n",
        "        res = factor\n",
        "        mssgs = [self.messages[factor][v] for v in f.variables]\n",
        "\n",
        "        res = factor * prod(mssgs)\n",
        "\n",
        "        return res.marginalize([v for v in f.variables if v not in variables], inplace=False)\n",
        "\n",
        "\n",
        "bp = MyBeliefPropagation(hmm_weather_3.to_factor_graph())\n",
        "bp.set_evidence({\"u0\":True,\"u1\":True, \"u2\":True})\n",
        "# print(bp.variables)\n",
        "bp.run_bp(root='w1')\n",
        "res = bp.get_marginal(['w0','w1','w2'])\n",
        "res.normalize(inplace=True)\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kv52Egu3Jxu"
      },
      "source": [
        "## Task 1: Robot Navigation on a Grid\n",
        "\n",
        "In this problem, a robot is wandering through the following small world:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Rq-izqt8vkkkX6FbWrhaeCuGkgggJiPF\"  alt=\"A robot on a maze\" title=\"Title text\" width=350 height=350>\n",
        "\n",
        "The robot can only occupy the colored squares.  At each time step, the robot attempts to move up, down, left or right, where the choice of direction is made at random.  If the robot attempts to move onto a black square, or to leave the confines of its world, its action has no effect and it does not move at all.  The robot can only sense the color of the square it occupies.  However, its sensors are only $90\\%$ accurate, meaning that $10\\%$ of the time, it perceives a random color rather than the true color of the currently occupied square.  The robot begins each walk in a randomly chosen colored square.\n",
        "\n",
        "In this problem, state refers to the location of the robot in the world in x:y coordinates, and output refers to a perceived color (r, g, b or y).  Thus, a typical random walk looks like this:\n",
        "\n",
        "``3:3 r``\n",
        "``3:3 r``\n",
        "``3:4 y``\n",
        "``2:4 b``\n",
        "``3:4 y``\n",
        "``3:3 r``\n",
        "``2:3 b``\n",
        "``1:3 g``\n",
        "``2:3 b``\n",
        "``2:4 r``\n",
        "``3:4 y``\n",
        "``4:4 y``\n",
        "\n",
        "Here, the robot begins in square ``3:3`` perceiving red, attempts to make an illegal move (to the right), so stays in ``3:3``, still perceiving red.  On the next step, the robot moves up to ``3:4`` perceiving yellow, then left to ``2:4`` perceiving blue (erroneously), and so on.\n",
        "\n",
        "We will provide the HMM model for this world. Then, given only sensor information (i.e., a sequence of colors), you will have to answer different queries regarding the actual path taken by the robot through its world.\n",
        "\n",
        "The data for this problem is in [robot.data](files/robot.data), a file containing $200$ training sequences (random walks) and $200$ test sequences, each sequence consisting of $200$ steps.\n",
        "\n",
        "We provide next the implementation on how to build the HMM. First, we define some functions that will become handy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3wnnbc13Jxv"
      },
      "outputs": [],
      "source": [
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "def split(s, sep):\n",
        "    \"\"\"\n",
        "    Generator that splits a sequence s into subsequences, when separator sep is found.\n",
        "    \"\"\"\n",
        "    chunk = []\n",
        "    for val in s:\n",
        "        if val == sep:\n",
        "            yield chunk\n",
        "            chunk = []\n",
        "        else:\n",
        "            chunk.append(val)\n",
        "    yield chunk\n",
        "\n",
        "def to_cpd(phi, x):\n",
        "    \"\"\"\n",
        "    Returns a TabularCPD object from a DiscreteFactor. For a given factor phi(x_0, ..., x_n)\n",
        "    and a variable x_i, it interprets the factor as a CPD P(x_i|Y), where Y is the set of all\n",
        "    variables in phi except x_i. I.e. P(x_i|x_0, ..., x_{i-1}, x_{i+1}, ..., x_n).\n",
        "    It also checks that the factor is a valid conditional probability distribution.\n",
        "    \"\"\"\n",
        "    assert x in phi.variables\n",
        "    idx = phi.variables.index(x)\n",
        "    card = list(phi.cardinality)\n",
        "    var_card = card[idx]\n",
        "    evidence_card = card[:idx] + card[idx+1:]\n",
        "    values = np.moveaxis(phi.values, idx, 0) # move variable x to dimension 0\n",
        "    return TabularCPD(variable=x,\n",
        "                      variable_card=var_card,\n",
        "                      evidence=phi.variables[:idx] + phi.variables[idx+1:],\n",
        "                      evidence_card=evidence_card,\n",
        "                      values=values.reshape(var_card, int(np.prod(evidence_card))), # int cast since np.prod([])=1.0\n",
        "                      state_names=phi.state_names)\n",
        "\n",
        "def normalize_cpd_values(variables, cardinality, values):\n",
        "    \"\"\"\n",
        "    Normalize a numpy array of CPD values. It also accounts for unreachable states (all 0s).\n",
        "    \"\"\"\n",
        "    assert len(variables) in (1,2)\n",
        "    f = DiscreteFactor(variables=variables, cardinality=cardinality, values=values)\n",
        "    # Normalize it as a CPD\n",
        "    f = to_cpd(f, variables[-1]) # Get the last variable for the CPD (e.g. [ht-1, ht] -> p(ht|ht-1))\n",
        "    f.normalize()\n",
        "    # Remove NaNs, put 0s instead\n",
        "    f.values[np.logical_not(np.isfinite(f.values))] = 0.0\n",
        "    if len(f.variables) == 2:\n",
        "        # The process f->cpd swapped the variables, let's swap them back\n",
        "        assert f.variables[1] == variables[0]\n",
        "        return np.transpose(f.values)\n",
        "    return f.values\n",
        "\n",
        "def get_hmm_factors(trajectories, h_states, v_states):\n",
        "    \"\"\"\n",
        "    Gets the prior, transition and observation probabilities of an HMM from data.\n",
        "    \"\"\"\n",
        "    prior = np.zeros(len(h_states))\n",
        "    transition = np.zeros([len(h_states), len(h_states)])\n",
        "    observation = np.zeros([len(h_states), len(v_states)])\n",
        "    for t in trajectories:\n",
        "        for i in range(len(t)):\n",
        "            s, o = t[i].split(\" \") # h and v come as a string \"h v\"\n",
        "            s_i, o_i = h_states.index(s), v_states.index(o)\n",
        "            if i == 0: # Prior\n",
        "                prior[s_i] += 1\n",
        "            else:\n",
        "                prev_s_i = h_states.index(t[i-1].split(\" \")[0])\n",
        "                transition[prev_s_i][s_i] += 1 # Transition\n",
        "            observation[s_i][o_i] += 1 # Observation\n",
        "\n",
        "    return normalize_cpd_values(['h0'], [len(h_states)], prior), \\\n",
        "           normalize_cpd_values(['ht-1', 'ht'], [len(h_states), len(h_states)], transition), \\\n",
        "           normalize_cpd_values(['ht', 'vt'], [len(h_states), len(v_states)], observation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daFL8Gwu3Jxw"
      },
      "source": [
        "Then, we extract the probabilities from the training sequences, and print one sample trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "zE-MW19f3Jxw"
      },
      "outputs": [],
      "source": [
        "with open(\"robot.data\") as f:\n",
        "    robot_data = f.read().splitlines() # this accounts for '\\n'\n",
        "\n",
        "# Split into train and test data (separated by \"..\" in the file, end of single trajectory is marked with \".\")\n",
        "train_robot, test_robot = [list(split(dataset, '.')) for dataset in split(robot_data, '..')]\n",
        "print(f\"ROBOT: {len(train_robot) + len(test_robot)} robot trajectories read.\")\n",
        "\n",
        "size_square = 4\n",
        "positions = [f\"{x+1}:{y+1}\" for x in range(size_square) for y in range(size_square)]\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "r_prior, r_transition, r_observation = get_hmm_factors(trajectories = train_robot,\n",
        "                                                       h_states=positions,\n",
        "                                                       v_states=colors) # This will raise a warning: invalid value encountered in true_divide\n",
        "\n",
        "# Define factor functions\n",
        "def robot_prior(pos):\n",
        "    return DiscreteFactor(variables=[pos],\n",
        "                          cardinality=[len(positions)],\n",
        "                          values=r_prior,\n",
        "                          state_names = {pos: positions})\n",
        "\n",
        "def robot_transition(prev_pos, next_pos):\n",
        "    return DiscreteFactor(variables=[prev_pos, next_pos],\n",
        "                          cardinality=[len(positions), len(positions)],\n",
        "                          values=r_transition,\n",
        "                          state_names = {prev_pos: positions,\n",
        "                                         next_pos: positions})\n",
        "\n",
        "def robot_observation(pos, col):\n",
        "    return DiscreteFactor(variables=[pos, col],\n",
        "                          cardinality=[len(positions), len(colors)],\n",
        "                          values=r_observation,\n",
        "                          state_names = {pos: positions,\n",
        "                                         col: colors})\n",
        "\n",
        "robot_pos_trajectories = [[f\"{p.split(' ')[0]}\" for p in traj] for traj in test_robot][:-1] # last one is empty\n",
        "robot_color_trajectories = [[f\"{p.split(' ')[1]}\" for p in traj] for traj in test_robot][:-1]\n",
        "\n",
        "print(robot_pos_trajectories[-1][:10])\n",
        "print(robot_color_trajectories[-1][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IdeX5Lt3Jxx"
      },
      "source": [
        "### Questions\n",
        "\n",
        "Given the following sequence of observations $v_{1:T}= V_{1:T}$:\n",
        "```\n",
        "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "```\n",
        "\n",
        "Answer the following questions using your implementation of belief propagation:\n",
        "1. Filtering : what is $p(h_6|v_{1:6}=V_{1:6})$?\n",
        "2. Prediction : what is $p(h_7|v_{1:6}=V_{1:6})$?\n",
        "3. Probability of evidence : what is $p(v_{1:T}=V_{1:T})$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPPmmEiQ3Jxy"
      },
      "outputs": [],
      "source": [
        "observed_colors = ['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "\n",
        "robot_HMM = HMM(n_vars=len(observed_colors),\n",
        "                prior_fn=robot_prior,\n",
        "                transition_fn=robot_transition,\n",
        "                observation_fn=robot_observation,\n",
        "                h_states=positions,\n",
        "                v_states=colors,\n",
        "                h_name=\"position\",\n",
        "                v_name=\"color\")\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_149nsY3Jxy"
      },
      "source": [
        "#### SOLUTION:\n",
        "Original trajectory:\n",
        "```\n",
        "robot_pos_trajectories[9][:15]\n",
        "['1:3', '1:3', '2:3', '2:4', '2:4', '2:3', '2:3', '2:4', '2:4', '3:4', '3:3', '2:3', '2:4', '3:4', '4:4']\n",
        "['g', 'g', 'b', 'r', 'r', 'b', 'b', 'r', 'r', 'y', 'r', 'b', 'r', 'y', 'b']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKjFRhMx3Jxz"
      },
      "source": [
        "## Task 2: Correcting typos without a dictionary\n",
        "\n",
        "The second domain deals with the problem of correcting typos in text without using a dictionary.  Here, you will be given text containing many typographical errors and the goal is to correct as many typos as possible.\n",
        "\n",
        "In this problem, state refers to the correct letter that should have been typed, and output refers to the actual letter that was typed.  Given a sequence of outputs (i.e., actually typed letters), the problem is to reconstruct the hidden state sequence (i.e., the intended sequence of letters).  Thus, data for this problem looks like this:\n",
        "\n",
        "<code>\n",
        "i i\n",
        "n n\n",
        "t t\n",
        "r r\n",
        "o o\n",
        "d x\n",
        "u u\n",
        "c c\n",
        "t t\n",
        "i i\n",
        "o i\n",
        "n n\n",
        "_ _\n",
        "t t\n",
        "h h\n",
        "e e\n",
        "_ _\n",
        "</code>\n",
        "\n",
        "\n",
        "where the left column is the correct text and the right column contains text with errors.\n",
        "\n",
        "Data for this problem was generated as follows: we started with a text document, in this case, the Unabomber's Manifesto, which was chosen not for political reasons, but as a convenient, on-line, single-author text of about the right length.  For simplicity, all numbers and punctuation were converted to white space and all letters converted to lower case.  The remaining text is a sequence only over the lower case letters and the space character, represented in the data files by an underscore character.  Next, typos were artificially added to the data as follows: with $90\\%$ probability, the correct letter is transcribed, but with $10\\%$ probability, a randomly chosen neighbor (on an ordinary physical keyboard) of the letter is transcribed instead.  Space characters are always transcribed correctly.  In a harder variant of the problem, the rate of errors is increased to $20\\%$.  The first (roughly) $20,000$ characters of the document have been set aside for testing.  The remaining $161,000$ characters are used for training.\n",
        "\n",
        "As an example, the original document begins:\n",
        "\n",
        "<code>introduction the industrial revolution and its consequences have been a disaster for the human race they have greatly increased the life expectancy of those of us who live in advanced countries but they have destabilized society\n",
        "</code>    \n",
        "    \n",
        "With $20\\%$ noise, it looks like this:\n",
        "\n",
        "<code>introductipn the industfial revolhtjon and its consequences bafw newn a diszster rkr the yumab race thdy have grwatky increased the ljte esoectandy od thosr of is who libe in advanced coubfries but they have fewtabipuzee xociwty</code>\n",
        "\n",
        "The error rate (fraction of  characters that are mistyped) is about $16.5\\%$ (less than $20\\%$ because space characters were not corrupted).\n",
        "\n",
        "Data for this part of the assignment is in [typos10.data](files/typos10.data) and [typos20.data](files/typos20.data), representing data generated with a $10\\%$ or $20\\%$ error rate, respectively.\n",
        "\n",
        "Next, we provide the code to get the HMM from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVmFTP5d3Jxz"
      },
      "outputs": [],
      "source": [
        "# 10% error rate\n",
        "with open(\"typos10.data\") as f:\n",
        "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
        "\n",
        "# Split into train and test data (separated by \"..\" in the file, end of single word is marked with \"_ _\")\n",
        "train_typos10, test_typos10 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
        "print(f\"TYPOS 10: {len(train_typos10) + len(test_typos10)} words read.\")\n",
        "\n",
        "characters = [chr(i+97) for i in range(26)]\n",
        "t10_prior, t10_transition, t10_observation = get_hmm_factors(trajectories = train_typos10,\n",
        "                                                             h_states=characters,\n",
        "                                                             v_states=characters)\n",
        "\n",
        "# 20% error rate\n",
        "with open(\"typos20.data\") as f:\n",
        "    text_data = f.read().splitlines() # this accounts for '\\n'\n",
        "train_typos20, test_typos20 = [list(split(dataset, '_ _')) for dataset in split(text_data, '..')]\n",
        "print(f\"TYPOS 20: {len(train_typos20) + len(test_typos20)} words read.\")\n",
        "t20_prior, t20_transition, t20_observation = get_hmm_factors(trajectories = train_typos20,\n",
        "                                                             h_states=characters,\n",
        "                                                             v_states=characters)\n",
        "\n",
        "# Define factor functions\n",
        "def text10_prior(c):\n",
        "    return DiscreteFactor(variables=[c],\n",
        "                          cardinality=[len(characters)],\n",
        "                          values=t10_prior,\n",
        "                          state_names = {c: characters})\n",
        "\n",
        "def text10_transition(prev_c, next_c):\n",
        "    return DiscreteFactor(variables=[prev_c, next_c],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t10_transition,\n",
        "                          state_names = {prev_c: characters,\n",
        "                                         next_c: characters})\n",
        "\n",
        "def text10_observation(c, c_typed):\n",
        "    return DiscreteFactor(variables=[c, c_typed],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t10_observation,\n",
        "                          state_names = {c: characters,\n",
        "                                         c_typed: characters})\n",
        "\n",
        "def text20_prior(c):\n",
        "    return DiscreteFactor(variables=[c],\n",
        "                          cardinality=[len(characters)],\n",
        "                          values=t20_prior,\n",
        "                          state_names = {c: characters})\n",
        "\n",
        "def text20_transition(prev_c, next_c):\n",
        "    return DiscreteFactor(variables=[prev_c, next_c],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t20_transition,\n",
        "                          state_names = {prev_c: characters,\n",
        "                                         next_c: characters})\n",
        "\n",
        "def text20_observation(c, c_typed):\n",
        "    return DiscreteFactor(variables=[c, c_typed],\n",
        "                          cardinality=[len(characters), len(characters)],\n",
        "                          values=t20_observation,\n",
        "                          state_names = {c: characters,\n",
        "                                         c_typed: characters})\n",
        "\n",
        "# Get test text from dataset\n",
        "original_text = \" \".join([\"\".join([c.split(\" \")[0] for c in word]) for word in test_typos10])\n",
        "typos10_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos10])\n",
        "typos20_text = \" \".join([\"\".join([c.split(\" \")[1] for c in word]) for word in test_typos20])\n",
        "print(\"Original text: \", original_text[:95])\n",
        "print(\"Typos 10% text:\", typos10_text[:95])\n",
        "print(\"Typos 20% text:\", typos20_text[:95])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIGeK_1B3Jx0"
      },
      "source": [
        "### Questions\n",
        "\n",
        "Given the following sequence of observations $v_{1:T}$:\n",
        "```\n",
        "['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
        "```\n",
        "\n",
        "Answer the following questions:\n",
        "1. Filtering : what is $p(h_{11}|v_{1:11}=V_{1:11})$?\n",
        "2. Prediction : what is $p(h_{12}|v_{1:11}=V_{1:11})$?\n",
        "3. Probability of evidence : what is $p(v_{1:11}=V_{1:11})$?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x62ue_Kt3Jx0"
      },
      "outputs": [],
      "source": [
        "word = ['i', 'n', 't', 'r', 'o', 'x', 'u', 'c', 't', 'i', 'i', 'n']\n",
        "\n",
        "word_hmm = HMM(n_vars=len(word),\n",
        "               prior_fn=text10_prior,\n",
        "               transition_fn=text10_transition,\n",
        "               observation_fn=text10_observation,\n",
        "               h_states=characters,\n",
        "               v_states=characters,\n",
        "               h_name=\"c\",\n",
        "               v_name=\"c_typed\")\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCHTwbdC3Jx1"
      },
      "source": [
        "## The Viterbi algorithm\n",
        "\n",
        "We have seen how we can obtain the MAP query from a BP query, and how that approach did not scale. Let's implement now the Viterbi algorithm to perform MAP queries on a HMM. It consists of the following steps\n",
        "\n",
        "1. Compute the factors $\\mu_t$ that will recursively be used to obtain the maximum probability\n",
        "\n",
        "$$\\mu(h_{t-1}) = \\max_{h_t} p(v_t|h_t)p(h_t|h_{t-1})\\mu(h_t),\\qquad 2\\leq t\\leq T,$$\n",
        "$$\\mu(h_T) = 1.$$\n",
        "\n",
        "2. Obtain the desired maximum probability and backtrack to obtain the state trajectory $h^*_{1:T}$ using the previous computations\n",
        "\n",
        "$$p_\\text{max} = \\text{max}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
        "$$h_1^* = \\text{argmax}_{h_1} p(v_1|h_1)p(h_1)\\mu(h_1),$$\n",
        "$$h_t^* = \\text{argmax}_{h_t} p(v_t|h_t)p(h_t|h_{t-1}^*)\\mu(h_t).$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXaJCWPr3Jx1"
      },
      "outputs": [],
      "source": [
        "def factor_ones(v, state_names):\n",
        "    \"\"\"\n",
        "    Returns a DiscreteFactor with all ones for variable v with its domain defined in states_names.\n",
        "    \"\"\"\n",
        "    card = len(state_names[v])\n",
        "    return DiscreteFactor(variables=[v],\n",
        "                          cardinality=[card],\n",
        "                          values=np.ones(card),\n",
        "                          state_names=state_names)\n",
        "\n",
        "class Viterbi:\n",
        "    def max_and_argmax(self, f):\n",
        "        \"\"\"\n",
        "        Given a factor f, returns its maximum value and the corresponding assignment. We assume that f\n",
        "        is a DiscreteFactor of one variable.\n",
        "        \"\"\"\n",
        "        assert len(f.variables)==1, \"Factor connected to more than one variable: \"+str(f.variables)\n",
        "        v = f.variables[0]\n",
        "        am = np.argmax(f.values)\n",
        "        return f.values[am], list(f.state_names[v])[am]\n",
        "\n",
        "    def compute_messages(self, hmm, evidence):\n",
        "        \"\"\"\n",
        "        Given an HMM and the evidence (a list of states in order from left to right), compute the\n",
        "        messages (from right to left).\n",
        "        Returns a list of messages.\n",
        "        \"\"\"\n",
        "        n_vars = len(evidence)\n",
        "        messages = [None]*n_vars\n",
        "\n",
        "        # IMPLEMENT\n",
        "\n",
        "        assert all(m is not None for m in messages)\n",
        "        return messages\n",
        "\n",
        "    def backtrack(self, hmm, messages, evidence):\n",
        "        \"\"\"\n",
        "        Given an HMM, the messages (computed from right to left), and the evidence (a list of states\n",
        "        in order from left to right), it computes the MAP states as well as their value in the joint\n",
        "        distribution.\n",
        "        Returns a list of states and the joint probability of these states.\n",
        "        \"\"\"\n",
        "        #IMPLEMENT: h0, compute MAP value\n",
        "        # ...\n",
        "        value, h0_opt = #...\n",
        "\n",
        "        map_h = [h0_opt]\n",
        "        for t in range(1, len(hmm.h)):\n",
        "            # ...\n",
        "            map_h.append(h_opt)\n",
        "        return map_h, value\n",
        "\n",
        "    def map_query(self, hmm, evidence):\n",
        "        \"\"\"\n",
        "        Given an hmm and the evidence (a list of states in order from left to right), returns the\n",
        "        MAP states as well as the MAP probability.\n",
        "        \"\"\"\n",
        "        assert type(evidence) in (list, tuple), \"The evidence should be a list of observed states\"\n",
        "        assert len(evidence) == len(hmm.v), \"To get the MAP of the states we need the whole sequence of observed states\"\n",
        "        messages = self.compute_messages(hmm, evidence)\n",
        "        return self.backtrack(hmm, messages, evidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "719oapWn3Jx2"
      },
      "source": [
        "### **MAP queries in the Basic setting**\n",
        "\n",
        "First we try it in our simple setting, and check that the result is the same as from the BP query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCxAtCNe3Jx2"
      },
      "outputs": [],
      "source": [
        "viterbi = Viterbi()\n",
        "map_states, map_prob = viterbi.map_query(hmm_weather_3, evidence=[True, True, True])\n",
        "print(\"MAP states:\", map_states)\n",
        "print(\"MAP prob:\", map_prob)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBcsE2JC3Jx3"
      },
      "source": [
        "How does this method compare, in terms of complexity, to our previous, naive, approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIsNoBeh3Jx3"
      },
      "source": [
        "---> Type your answer here ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZ9i7HfW3Jx4"
      },
      "source": [
        "<a name=\"MAP-robot\"></a>\n",
        "\n",
        "### **MAP queries in the robot navigation setting**\n",
        "\n",
        "To try it in the robot navigation setting, let's first define the `DiscreteFactor` functions for the HMM model, according to the values extracted from the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZAEqXNA3Jx4"
      },
      "outputs": [],
      "source": [
        "observed_colors = robot_color_trajectories[4]\n",
        "actual_trajectory = robot_pos_trajectories[4]\n",
        "\n",
        "robot_HMM = # ...\n",
        "map_states, map_value = # ...\n",
        "\n",
        "print(\"Traj:\", observed_colors)\n",
        "print(\"Infered traj.: \", map_states)\n",
        "print(\"Solution:      \", actual_trajectory)\n",
        "print(\"MAP value:\", map_value)\n",
        "\n",
        "def error(t1, t2):\n",
        "    error = 0\n",
        "    for c1, c2 in zip(t1, t2):\n",
        "        if c1 != c2:\n",
        "            error += 1\n",
        "    return error/len(t1)\n",
        "\n",
        "print(\"Error:\", error(map_states, actual_trajectory))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI7Czszu3Jx4"
      },
      "source": [
        "<a name=\"MAP-words\"></a>\n",
        "### **MAP queries in the typo correction setting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDix-T8w3Jx4"
      },
      "source": [
        "Correct the following word containing typos with the HMM:\n",
        "\n",
        "```['i','n','t','r','o','x','u','c','t','i','i','n']```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4fynBY63Jx4"
      },
      "outputs": [],
      "source": [
        "map_states, map_value = # ...\n",
        "\n",
        "print(map_states)\n",
        "print(map_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXEMSps43Jx5"
      },
      "source": [
        "Now, let's correct the full text. We have the original text and the one that contains typos in the variables original_text and typos10_text respectively. We provide a function above to test the error between two texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWyE6Kun3Jx5"
      },
      "outputs": [],
      "source": [
        "rec10_text = []\n",
        "for word in typos10_text.split(\" \"):\n",
        "    chs = [c for c in word]\n",
        "\n",
        "    # ...\n",
        "    # build hmm model\n",
        "    # run viterbi to get MAP states\n",
        "\n",
        "    new_word = # ...\n",
        "    rec10_text.append(\"\".join(new_word))\n",
        "rec10_text = \" \".join(rec10_text)\n",
        "\n",
        "print(\"Corrected:\", error(rec10_text, original_text))\n",
        "print(\"Not corrected:\", error(typos10_text, original_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynytolmY3Jx5"
      },
      "source": [
        "Do the same for the case of 20% of error rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCRJiNCo3Jx5"
      },
      "outputs": [],
      "source": [
        "rec20_text = []\n",
        "# IMPLEMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nI78Lw5y3Jx6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}